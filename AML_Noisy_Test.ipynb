{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RefineX/Change-Detection/blob/main/AML_Noisy_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Downloader\n",
        "dataset = \"WHU\" #@param [\"S2Looking\", \"LEVIRCD_Plus\", \"WHU\"]\n",
        "resize = \"512\" #@param [\"1024\", \"512\", \"256\"]\n",
        "crop = \"256\" #@param [\"1024\", \"512\", \"256\"]\n",
        "\n",
        "data_link_dict = {\n",
        "    'S2Looking': {\n",
        "      '1024_512': \"1-0_vcODMYmyYIY_uhMcs97aAk2OJVduq&confirm=t\",\n",
        "      '1024_256': \"1-0mVd6BjKnG3LXhYkbyxdx0-dtRKY6KO&confirm=t\",\n",
        "      '512_512': \"1-6WOmE0LTJ4Z31EphmA0L8QY5NMMllsT&confirm=t\",\n",
        "      '512_256': \"1-7NSOmHTsDpkEtbgt_N4VSgipCo5kr3a&confirm=t\",\n",
        "      '256_256': \"1-8x5d5DrNsgJ5eAOYyKwi91g8knGeRjQ&confirm=t\",\n",
        "      '1024_1024': \"1GzrgMwJKguXSWSfFsBSC2qSr52fVEc7W&confirm=t\"\n",
        "    },\n",
        "    'LEVIRCD_Plus': {\n",
        "      '1024_512': \"1-22GjfF8mlLFNyoJaa6_GMJRfTCoGZyc&confirm=t\",\n",
        "      '1024_256': \"1-2r-zCCfQjLRtwwXMGPYAxEJcTS8Hp80&confirm=t\",\n",
        "      '512_512': \"1-43scZrxe3Q_PH2EnBRuc_6l9O9WjPs2&confirm=t\",\n",
        "      '512_256': \"1-5oC0xV36S4K5VMiQuwheWoyMt1ymYb9&confirm=t\",\n",
        "      '256_256': \"1-69cdgqlcXunt5vrCR9jRvcMkpPNzYWr&confirm=t\",\n",
        "      '1024_1024': \"1nyPJZGGOL7o8A0m0rGw7wyu2BFIxC4SD&confirm=t\"\n",
        "    },\n",
        "    'WHU': {\n",
        "      '1024_512': \"1-22GjfF8mlLFNyoJaa6_GMJRfTCoGZyc&confirm=t\",\n",
        "      '1024_256': \"1aLl-squfjxvQhpqs0Y7Xz8eMwC2Vrttw&confirm=t\",\n",
        "      '512_512': \"1-43scZrxe3Q_PH2EnBRuc_6l9O9WjPs2&confirm=t\",\n",
        "      '512_256': \"10ui3sAPdOmCcrJO5cVjFEakMf5W8lwt6&confirm=t\",\n",
        "      '256_256': \"1xFRwJJvLjpUsEVQVHkxCulP4Ts92OABM&confirm=t\",\n",
        "      '1024_1024': \"1nyPJZGGOL7o8A0m0rGw7wyu2BFIxC4SD&confirm=t\"\n",
        "    }\n",
        "}\n",
        "\n",
        "import os\n",
        "if os.path.exists(f'Data/{dataset}/{resize}_{crop}'):\n",
        "  print('This dataset already exists.')\n",
        "else:\n",
        "  gdown_link = data_link_dict[dataset][f'{resize}_{crop}']\n",
        "  !gdown \"{gdown_link}\"\n",
        "  print('Unzipping...',end='')\n",
        "  !unzip -q \"{resize}_{crop}.zip\"\n",
        "  print('Done.\\nDeleting zip...',end='')\n",
        "  !rm \"{resize}_{crop}.zip\"\n",
        "  print('Done.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jdXkHvK6gGr7",
        "outputId": "55511503-4fc9-4b8f-cd9c-418b514af438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10ui3sAPdOmCcrJO5cVjFEakMf5W8lwt6&confirm=t\n",
            "To: /content/512_256.zip\n",
            "\r  0% 0.00/27.2M [00:00<?, ?B/s]\r 17% 4.72M/27.2M [00:00<00:00, 46.2MB/s]\r100% 27.2M/27.2M [00:00<00:00, 141MB/s] \n",
            "Unzipping...Done.\n",
            "Deleting zip...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "# import os\n",
        "# import time\n",
        "import numpy as np\n",
        "# from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "# from IPython import display\n",
        "import cv2\n",
        "import pywt\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "B9GQ_AA1i5Ji"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Characteristics\n",
        "dataset = \"WHU\" #@param [\"S2Looking\", \"LEVIRCD_Plus\", \"WHU\"]\n",
        "resized_size = \"512\" #@param [1024, 512, 256]\n",
        "crop_size = \"256\" #@param [1024, 512, 256]\n",
        "resized_size = int(resized_size)\n",
        "crop_size = int(crop_size)\n",
        "if dataset == 'S2Looking':\n",
        "  pre_image = 'Image1'\n",
        "  post_image = 'Image2'\n",
        "else:\n",
        "  pre_image = 'A'\n",
        "  post_image = 'B'\n",
        "label_image = 'label'\n",
        "PATH = f\"/content/Data/{dataset}/{resized_size}_{crop_size}\"\n",
        "Path('saved/models/').mkdir(parents=True, exist_ok=True)\n",
        "Path('saved/histories/').mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AFi5x75Ek8IF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "\n",
        "def iou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou_value = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "def miou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  tn = tf.cast(tf.reduce_sum((1-y_pred)*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou1 = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  iou2 = (tn + 1e-14) / (tn + fp + fn + 1e-14)\n",
        "  iou_value = (iou1 + iou2) / 2\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "# Losses"
      ],
      "metadata": {
        "id": "JGxDUbzFp6IW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# from classification_models.tfkeras import Classifiers\n",
        "# import pickle\n",
        "# from tensorflow.keras import mixed_precision\n",
        "# mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "O3mqAH-HyxjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = 50\n",
        "# es_patience = 15\n",
        "# rLR_patience = 5\n",
        "# lr = 1e-2\n",
        "# optimizer = Adam(learning_rate = lr)\n",
        "# loss = 'categorical_crossentropy'\n",
        "# BATCH_SIZE = 16\n",
        "# metrics = [iou, 'accuracy']"
      ],
      "metadata": {
        "id": "3UI_uqydsmA9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Noisy Test"
      ],
      "metadata": {
        "id": "txklvqKoedmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "data_augmentation = \"none\" #@param [\"none\", \"edge_augmented\", \"mra_augmented\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "57UX_ILkt_im"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions for Model #1\n",
        "\n",
        "def salt_and_pepper_noise(image):\n",
        "  noisy_image = image\n",
        "  uniform_noise = tf.random.uniform((crop_size, crop_size),0,1)\n",
        "  uniform_noise = tf.stack([uniform_noise]*noisy_image.shape[-1],axis=-1)\n",
        "  # uniform_noise = tf.random.uniform(shape=image[..., -1:].shape)\n",
        "  power = 0.025\n",
        "  # noisy_image[uniform_noise < power] = 0\n",
        "  noisy_image = tf.where(uniform_noise < power, tf.zeros_like(noisy_image), noisy_image)\n",
        "  noisy_image = tf.where(uniform_noise > (1-power), tf.ones_like(noisy_image), noisy_image)\n",
        "  return noisy_image\n",
        "\n",
        "def gaussian_noise(image):\n",
        "  noisy_image = image\n",
        "  power = 0.2\n",
        "  noisy_image = noisy_image + (tf.random.normal(noisy_image.shape) * power)\n",
        "  ni_max = tf.reduce_max(noisy_image)\n",
        "  ni_min = tf.reduce_min(noisy_image)\n",
        "  noisy_image = (noisy_image - ni_min) / (ni_max - ni_min)\n",
        "  return noisy_image\n",
        "\n",
        "# Edge Augmentation\n",
        "def canny_edge(image):\n",
        "  l,u = 100, 200\n",
        "  edgesA = cv2.Canny(image[:,:,:3].numpy()[:,:,::-1], l, u)\n",
        "  edgesB = cv2.Canny(image[:,:,3:].numpy()[:,:,::-1], l, u)\n",
        "  edges = tf.stack([edgesA,edgesB],axis=-1)\n",
        "  edges = tf.cast(edges,tf.float32)\n",
        "  edges /= tf.reduce_max(edges)\n",
        "  return edges\n",
        "\n",
        "# MRA Augmentation\n",
        "def mra_haar(image):\n",
        "\n",
        "  decomp = pywt.wavedec2(cv2.cvtColor(image[:,:,:3].numpy(),cv2.COLOR_RGB2GRAY),wavelet='haar',mode='constant',level=1)\n",
        "  h_dA = decomp[1][0]\n",
        "  h_dA = (h_dA-h_dA.min())/(h_dA.max()-h_dA.min())\n",
        "  h_dA = cv2.resize(h_dA, (crop_size,crop_size), cv2.INTER_LINEAR)\n",
        "  v_dA = decomp[1][1]\n",
        "  v_dA = (v_dA-v_dA.min())/(v_dA.max()-v_dA.min())\n",
        "  v_dA = cv2.resize(v_dA, (crop_size,crop_size), cv2.INTER_LINEAR)\n",
        "  d_dA = decomp[1][2]\n",
        "  d_dA = (d_dA-d_dA.min())/(d_dA.max()-d_dA.min())\n",
        "  d_dA = cv2.resize(d_dA, (crop_size,crop_size), cv2.INTER_LINEAR)\n",
        "\n",
        "  decomp = pywt.wavedec2(cv2.cvtColor(image[:,:,3:].numpy(),cv2.COLOR_RGB2GRAY),wavelet='haar',mode='constant',level=1)\n",
        "  h_dB = decomp[1][0]\n",
        "  h_dB = (h_dB-h_dB.min())/(h_dB.max()-h_dB.min())\n",
        "  h_dB = cv2.resize(h_dB, (crop_size,crop_size), cv2.INTER_LINEAR)\n",
        "  v_dB = decomp[1][1]\n",
        "  v_dB = (v_dB-v_dB.min())/(v_dB.max()-v_dB.min())\n",
        "  v_dB = cv2.resize(v_dB, (crop_size,crop_size), cv2.INTER_LINEAR)\n",
        "  d_dB = decomp[1][2]\n",
        "  d_dB = (d_dB-d_dB.min())/(d_dB.max()-d_dB.min())\n",
        "  d_dB = cv2.resize(d_dB, (crop_size,crop_size), cv2.INTER_LINEAR)\n",
        "  edges = tf.stack([h_dA, v_dA, d_dA, h_dB, v_dB, d_dB],axis=-1)\n",
        "  edges = tf.cast(edges,tf.float32)\n",
        "\n",
        "  return edges\n",
        "\n",
        "def load(imageA_file):\n",
        "  imageA = tf.io.read_file(imageA_file)\n",
        "  imageA = tf.image.decode_png(imageA)[:,:,:3]\n",
        "\n",
        "  imageB_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{post_image}/')\n",
        "  imageB = tf.io.read_file(imageB_file)\n",
        "  imageB = tf.image.decode_jpeg(imageB)[:,:,:3]\n",
        "\n",
        "  label_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{label_image}/')\n",
        "  label_file = tf.strings.regex_replace(label_file, '.jpg', '.png')\n",
        "  label = tf.io.read_file(label_file)\n",
        "  label = tf.image.decode_png(label)[:,:,0]\n",
        "\n",
        "  imageA = tf.cast(imageA,tf.float32)\n",
        "  imageB = tf.cast(imageB,tf.float32)\n",
        "  image = tf.concat([imageA,imageB],axis=-1)\n",
        "  label = tf.cast(label,tf.float32)\n",
        "  label = tf.stack([255-label,label],axis=-1)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def normalize(image, label):\n",
        "  image = image / 255\n",
        "  label = label / 255\n",
        "  return image, label\n",
        "\n",
        "def load_image(image_file):\n",
        "  image, label = load(image_file)\n",
        "  image, label = normalize(image, label)\n",
        "  noisy_image = tf.py_function(gaussian_noise, [image], tf.float32)\n",
        "  noisy_image = tf.cast(noisy_image * 255,tf.uint8)\n",
        "  if data_augmentation == 'edge_augmented':\n",
        "    edges = tf.py_function(canny_edge, [noisy_image], tf.float32)\n",
        "  elif data_augmentation == 'mra_augmented':\n",
        "    edges = tf.py_function(mra_haar, [noisy_image], tf.float32)\n",
        "  noisy_image = tf.cast(noisy_image / 255,tf.float32)\n",
        "  if data_augmentation != 'none':\n",
        "    noisy_image = tf.concat([noisy_image,edges],axis=-1)\n",
        "  return noisy_image, label\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(f'{PATH}/test/{pre_image}/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset_length = len(test_dataset)\n",
        "\n",
        "print(f'test_dataset_length: {test_dataset_length}')"
      ],
      "metadata": {
        "id": "dXKU1Hz3edGf",
        "outputId": "c50509fb-a886-411d-92c0-43c5c25b29b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_dataset_length: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1eOeFpU2Fl4Ekn0ytqjMLVP4CuMP8xl-M&confirm=t\""
      ],
      "metadata": {
        "id": "624fqWiE1yx2",
        "outputId": "aa9ce454-a516-4eae-8cd3-45f948472f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eOeFpU2Fl4Ekn0ytqjMLVP4CuMP8xl-M&confirm=t\n",
            "To: /content/LEVIRCD_Plus_resnet18_model_ef_mra_haar_0.5603.zip\n",
            "100% 156M/156M [00:02<00:00, 59.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip LEVIRCD_Plus_resnet18_model_ef_mra_haar_0.5603.zip"
      ],
      "metadata": {
        "id": "d8srg6Fm167Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelpath = '/content/saved/models/LEVIRCD_Plus_resnet18_model_ef_canny1_0.5714.h5'"
      ],
      "metadata": {
        "id": "zcNmg0yVtYAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(modelpath, custom_objects={'iou':iou})\n",
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "gqr5dmDftiy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"1QwvuA0Bn0wwiJ3ZnWOYsQw7PJfLQCFWh&confirm=t\""
      ],
      "metadata": {
        "id": "liYpkUkg2mGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelpath = '/content/saved/models/LEVIRCD_Plus_resnet18_model_ef_mra_haar_0.5603.h5'"
      ],
      "metadata": {
        "id": "_VwMbmyE2Xlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset test - unaugmented\n",
        "# for x,y in test_dataset.take(1):\n",
        "#   pass\n",
        "# idx = 0\n",
        "# plt.figure(figsize=(3*10,10))\n",
        "# plt.subplot(131)\n",
        "# plt.imshow(x[idx,:,:,:3].numpy())\n",
        "# plt.subplot(132)\n",
        "# plt.imshow(x[idx,:,:,3:6].numpy())\n",
        "# plt.subplot(133)\n",
        "# plt.imshow(y[idx].numpy().argmax(-1),cmap='gray')"
      ],
      "metadata": {
        "id": "1PaejykHoA-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset test - edge augmented\n",
        "# for x,y in test_dataset.take(1):\n",
        "#   pass\n",
        "# idx = 0\n",
        "# plt.figure(figsize=(20,4))\n",
        "# plt.subplot(151)\n",
        "# plt.imshow(x[idx,:,:,:3].numpy())\n",
        "# plt.subplot(152)\n",
        "# plt.imshow(x[idx,:,:,6].numpy(),cmap='gray')\n",
        "# plt.subplot(153)\n",
        "# plt.imshow(x[idx,:,:,3:6].numpy())\n",
        "# plt.subplot(154)\n",
        "# plt.imshow(x[idx,:,:,7].numpy(),cmap='gray')\n",
        "# plt.subplot(155)\n",
        "# plt.imshow(y[idx].numpy().argmax(-1),cmap='gray')"
      ],
      "metadata": {
        "id": "2fgVPgUNxxoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset test - mra augmented\n",
        "# for x,y in test_dataset.take(1):\n",
        "#   pass\n",
        "# idx = 5\n",
        "# plt.figure(figsize=(40,16))\n",
        "# plt.subplot(251)\n",
        "# plt.imshow(x[idx,:,:,:3].numpy())\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(252)\n",
        "# plt.imshow(x[idx,:,:,6].numpy(),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(256)\n",
        "# plt.imshow(x[idx,:,:,7].numpy(),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(257)\n",
        "# plt.imshow(x[idx,:,:,8].numpy(),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(253)\n",
        "# plt.imshow(x[idx,:,:,3:6].numpy())\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(254)\n",
        "# plt.imshow(x[idx,:,:,9].numpy(),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(258)\n",
        "# plt.imshow(x[idx,:,:,10].numpy(),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(259)\n",
        "# plt.imshow(x[idx,:,:,11].numpy(),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.subplot(255)\n",
        "# plt.imshow(y[idx].numpy().argmax(-1),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout()"
      ],
      "metadata": {
        "id": "obd8hL-61AdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move savefile to drive"
      ],
      "metadata": {
        "id": "7uqiwkibhyo8"
      }
    }
  ]
}